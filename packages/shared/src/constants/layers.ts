/**
 * Layer Constants and Configurations
 */

import { LayerConfig, LayerType } from '../types'

export const LAYER_CONFIGS: Record<LayerType, LayerConfig> = {
  input: {
    type: 'input',
    name: 'Input',
    icon: 'ğŸ“¥',
    category: 'input',
    description: 'Input layer that defines the shape of your data',
    defaultParams: {
      type: 'input',
      shape: '224,224,3',
      preprocessing: 'normalize',
    },
    requiredParams: ['shape'],
    commonUses: ['Start of every network', 'Define data dimensions'],
  },
  conv2d: {
    type: 'conv2d',
    name: 'Conv2D',
    icon: 'ğŸ”²',
    category: 'convolutional',
    description: '2D convolution layer for image feature extraction',
    defaultParams: {
      type: 'conv2d',
      filters: 32,
      kernelSize: 3,
      strides: 1,
      padding: 'same',
      activation: 'relu',
      batchNorm: false,
    },
    requiredParams: ['filters', 'kernelSize'],
    commonUses: ['Image classification', 'Feature extraction', 'Object detection'],
  },
  dense: {
    type: 'dense',
    name: 'Dense (Fully Connected)',
    icon: 'ğŸ”—',
    category: 'dense',
    description: 'Fully connected layer that learns complex patterns',
    defaultParams: {
      type: 'dense',
      units: 128,
      activation: 'relu',
      useBias: true,
    },
    requiredParams: ['units'],
    commonUses: ['Classification head', 'Feature combination', 'Final predictions'],
  },
  dropout: {
    type: 'dropout',
    name: 'Dropout',
    icon: 'ğŸ’§',
    category: 'normalization',
    description: 'Randomly drops connections to prevent overfitting',
    defaultParams: {
      type: 'dropout',
      rate: 0.5,
    },
    requiredParams: ['rate'],
    commonUses: ['Regularization', 'Reduce overfitting', 'After dense layers'],
  },
  pooling: {
    type: 'pooling',
    name: 'Pooling',
    icon: 'ğŸ“‰',
    category: 'pooling',
    description: 'Downsamples feature maps to reduce dimensions',
    defaultParams: {
      type: 'pooling',
      poolType: 'max',
      poolSize: 2,
      strides: 2,
      padding: 'valid',
    },
    requiredParams: ['poolType', 'poolSize'],
    commonUses: ['Dimension reduction', 'Translation invariance', 'After conv layers'],
  },
  batchnorm: {
    type: 'batchnorm',
    name: 'Batch Normalization',
    icon: 'ğŸ“Š',
    category: 'normalization',
    description: 'Normalizes activations to stabilize training',
    defaultParams: {
      type: 'batchnorm',
    },
    requiredParams: [],
    commonUses: ['Faster training', 'Higher learning rates', 'After conv/dense layers'],
  },
  flatten: {
    type: 'flatten',
    name: 'Flatten',
    icon: 'ğŸ“',
    category: 'other',
    description: 'Flattens multi-dimensional input into 1D',
    defaultParams: {
      type: 'flatten',
    },
    requiredParams: [],
    commonUses: ['Before dense layers', 'Connect conv to dense', 'Prepare for output'],
  },
  lstm: {
    type: 'lstm',
    name: 'LSTM',
    icon: 'ğŸ”',
    category: 'recurrent',
    description: 'Long Short-Term Memory for sequential data',
    defaultParams: {
      type: 'lstm',
      units: 128,
      returnSequences: false,
      dropout: 0.0,
      recurrentDropout: 0.0,
    },
    requiredParams: ['units'],
    commonUses: ['Time series', 'NLP', 'Sequential prediction'],
  },
  gru: {
    type: 'gru',
    name: 'GRU',
    icon: 'ğŸ”„',
    category: 'recurrent',
    description: 'Gated Recurrent Unit, lighter alternative to LSTM',
    defaultParams: {
      type: 'gru',
      units: 128,
      returnSequences: false,
    },
    requiredParams: ['units'],
    commonUses: ['Time series', 'NLP', 'Faster than LSTM'],
  },
  transformer: {
    type: 'transformer',
    name: 'Transformer',
    icon: 'ğŸ¯',
    category: 'other',
    description: 'Self-attention mechanism for sequence modeling',
    defaultParams: {
      type: 'transformer',
      heads: 8,
      keyDim: 64,
      ffDim: 512,
      dropout: 0.1,
    },
    requiredParams: ['heads', 'keyDim', 'ffDim'],
    commonUses: ['NLP', 'Vision transformers', 'Attention-based models'],
  },
  attention: {
    type: 'attention',
    name: 'Attention',
    icon: 'ğŸ‘ï¸',
    category: 'other',
    description: 'Attention mechanism for focusing on important features',
    defaultParams: {
      type: 'attention',
      heads: 8,
      keyDim: 64,
      dropout: 0.1,
    },
    requiredParams: ['heads', 'keyDim'],
    commonUses: ['Sequence-to-sequence', 'Machine translation', 'Image captioning'],
  },
  embedding: {
    type: 'embedding',
    name: 'Embedding',
    icon: 'ğŸ“–',
    category: 'other',
    description: 'Converts discrete tokens to dense vectors',
    defaultParams: {
      type: 'embedding',
    },
    requiredParams: [],
    commonUses: ['NLP', 'Word embeddings', 'Token representation'],
  },
  residual: {
    type: 'residual',
    name: 'Residual Connection',
    icon: 'â†ªï¸',
    category: 'other',
    description: 'Skip connection for deeper networks (ResNet)',
    defaultParams: {
      type: 'residual',
    },
    requiredParams: [],
    commonUses: ['Deep networks', 'Prevent vanishing gradients', 'ResNet architecture'],
  },
  globalavgpool: {
    type: 'globalavgpool',
    name: 'Global Average Pooling',
    icon: 'ğŸŒ',
    category: 'pooling',
    description: 'Averages across entire feature map',
    defaultParams: {
      type: 'globalavgpool',
    },
    requiredParams: [],
    commonUses: ['Before output layer', 'Alternative to flatten', 'Reduce parameters'],
  },
  globalmaxpool: {
    type: 'globalmaxpool',
    name: 'Global Max Pooling',
    icon: 'ğŸ”',
    category: 'pooling',
    description: 'Takes maximum across entire feature map',
    defaultParams: {
      type: 'globalmaxpool',
    },
    requiredParams: [],
    commonUses: ['Before output layer', 'Extract dominant features'],
  },
  conv3d: {
    type: 'conv3d',
    name: 'Conv3D',
    icon: 'ğŸ§Š',
    category: 'convolutional',
    description: '3D convolution for video and volumetric data',
    defaultParams: {
      type: 'conv3d',
    },
    requiredParams: [],
    commonUses: ['Video classification', 'Medical imaging', '3D data'],
  },
}

export const LAYER_CATEGORIES = {
  input: { name: 'Input', color: '#10b981', icon: 'ğŸ“¥' },
  convolutional: { name: 'Convolutional', color: '#3b82f6', icon: 'ğŸ”²' },
  dense: { name: 'Dense', color: '#8b5cf6', icon: 'ğŸ”—' },
  recurrent: { name: 'Recurrent', color: '#f59e0b', icon: 'ğŸ”' },
  normalization: { name: 'Normalization', color: '#06b6d4', icon: 'ğŸ“Š' },
  pooling: { name: 'Pooling', color: '#14b8a6', icon: 'ğŸ“‰' },
  other: { name: 'Other', color: '#6b7280', icon: 'ğŸ”§' },
}
